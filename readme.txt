
爬虫思路: 1获取网页html 2根据规律解析HTML

设计思路：
根据豆瓣的网页结构，首先可以分析计算出编程类图书一共有多少页，爬虫启动的时候首先会生成所有的URL放入
UrlQueue中，然后根据启动线程数，与线程抓取网页间隔（防止被豆瓣屏蔽）预估出所需时间。
多PageParser线程分别去取UrlQueue中的url，获取该页面信息，根据dom元素结构来取得图书信息，
放入ResultData中，最终UrlQueue为空时所有PageParser停止运行，程序开始导出一个简单的csv文件。
并在控制台打印出一些解析出错的书籍。程序终止。并打印总耗时。
---coast time :248290ms . and book totle size is :1000

生成文件在export目录下
主程序入口为ClawlerApp
建议运行时长: 爬取信息结束后程序自动终止

关于代理，因为我这边网络环境不佳，有时与代理IP的连接都超时，故无法使用。
在此处仅简述原理，使用本机保存一份代理IP与端口的文件，包含多个代理IP，
PageParser再获取网页的时候，每次均使用httpClient来设置不同代理地址并获取网页信息。
这样既可避免被豆瓣封IP地址。加速爬虫采集效率。
